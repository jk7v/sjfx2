import json
import streamlit as st
from openai import OpenAI
# å‡è®¾ common.py å·²å­˜åœ¨ get_llm_response æ–¹æ³•ï¼Œå¦åˆ™éœ€è¡¥å……
from common import get_llm_response

def get_answer(question: str, api_vendor, base_url, api_key, model_name):
    try:
        client = OpenAI(base_url=base_url, api_key=api_key)
        memory = []
        for role, content in st.session_state['messages']:
            if role == 'human':
                memory.append({'role': 'user', 'content': content})
            else:
                memory.append({'role': 'assistant', 'content': content})
        if api_vendor == 'DeepSeek':
            return get_llm_response(client, model=model_name, user_prompt=question, memory=memory, stream=True)
        else:
            return get_llm_response(client, model=model_name, user_prompt=question, memory=memory)
    except Exception as e:
        return f'å°ğŸ–æš‚æ—¶æ— æ³•æä¾›å›å¤ï¼Œé”™è¯¯ä¿¡æ¯ï¼š{e}'

st.set_page_config(page_title="å°ğŸ–èŠå¤©æœºå™¨äºº", page_icon="ğŸ¤–", layout="wide")

# è®¾ç½®é¡µé¢æ ·å¼
st.markdown("""
<style>
    /* æ•´ä½“èƒŒæ™¯ */
    .stApp {
        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
    }
    
    /* ä¾§è¾¹æ æ ·å¼ */
    .css-1d391kg, .css-1p05t8e {
        background-color: rgba(255, 255, 255, 0.8);
        backdrop-filter: blur(10px);
        border-right: 1px solid rgba(255, 255, 255, 0.3);
    }
    
    /* èŠå¤©æ¶ˆæ¯æ ·å¼ */
    .stChatMessage {
        background-color: rgba(255, 255, 255, 0.9);
        border-radius: 15px;
        padding: 15px;
        margin: 10px 0;
        box-shadow: 0 2px 6px rgba(0, 0, 0, 0.05);
        transition: transform 0.2s;
    }
    
    .stChatMessage:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
    }
    
    /* ç”¨æˆ·æ¶ˆæ¯æ ·å¼ */
    .stChatMessage.user {
        background: linear-gradient(135deg, #007AFF 0%, #5B5BFF 100%);
        color: white;
    }
    
    /* AIæ¶ˆæ¯æ ·å¼ */
    .stChatMessage.assistant {
        background: linear-gradient(135deg, #E8E8E8 0%, #FFFFFF 100%);
    }
    
    /* è¾“å…¥æ¡†æ ·å¼ */
    .stChatInput {
        border-radius: 20px;
        border: 1px solid rgba(0, 0, 0, 0.1);
        padding: 10px 20px;
        background: rgba(255, 255, 255, 0.9);
        box-shadow: 0 2px 6px rgba(0, 0, 0, 0.05);
    }
    
    /* æŒ‰é’®æ ·å¼ */
    .stButton>button {
        border-radius: 20px;
        padding: 10px 25px;
        background: linear-gradient(135deg, #007AFF 0%, #5B5BFF 100%);
        color: white;
        border: none;
        transition: all 0.3s ease;
    }
    
    .stButton>button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
    }
    
    /* æ ‡é¢˜æ ·å¼ */
    h2 {
        color: #2C3E50;
        font-weight: 600;
        text-align: center;
        margin: 20px 0;
        text-shadow: 1px 1px 2px rgba(0, 0, 0, 0.1);
    }
</style>
""", unsafe_allow_html=True)

with st.sidebar:
    api_vendor = st.radio(label='è¯·é€‰æ‹©æœåŠ¡æä¾›å•†: ', options=['OpenAI', 'DeepSeek'])
    if api_vendor == 'OpenAI':
        base_url = 'https://twapi.openai-hk.com/v1/'
        model_options = ['gpt-4o-mini', 'gpt-3.5-turbo', 'gpt-4o', 'gpt-4.1-mini', 'gpt-4.1']
    elif api_vendor == 'DeepSeek':
        base_url = 'https://api.deepseek.com'
        model_options = ['deepseek-chat', 'deep-reasoner']
    else:
        base_url = ''
        model_options = []
    model_name = st.selectbox(label='è¯·é€‰æ‹©è¦ä½¿ç”¨çš„æ¨¡å‹: ', options=model_options)
    api_key = st.text_input(label='è¯·è¾“å…¥ä½ çš„key', type='password')

if 'messages' not in st.session_state:
    st.session_state['messages'] = [('ai', 'ä½ å¥½ï¼Œæˆ‘æ˜¯ä½ çš„AIåŠ©æ‰‹ï¼Œæˆ‘å«å°ğŸ–ã€‚')]

st.write('## å°ğŸ–èŠå¤©æœºå™¨äºº')

for role, content in st.session_state['messages']:
    st.chat_message(role).write(content)

user_input = st.chat_input(placeholder='è¯·è¾“å…¥')
if user_input:
    st.session_state['messages'].append(('human', user_input))
    st.chat_message('human').write(user_input)
    with st.spinner('å°ğŸ–æ­£åœ¨æ€è€ƒï¼Œè¯·è€å¿ƒç­‰å¾…â€¦â€¦'):
        if api_vendor == 'DeepSeek':
            stream = get_answer(user_input, api_vendor, base_url, api_key, model_name)
            st.session_state['messages'].append(('ai', ''))
            msg = st.chat_message('ai')
            text = ''
            for chunk in st.write_stream(stream):
                text += chunk
            st.session_state['messages'][-1] = ('ai', text)
        else:
            answer = get_answer(user_input, api_vendor, base_url, api_key, model_name)
            st.session_state['messages'].append(('ai', answer))
            st.chat_message('ai').write(answer)